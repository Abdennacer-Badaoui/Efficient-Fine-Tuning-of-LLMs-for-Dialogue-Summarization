# Efficient-Fine-Tuning-of-LLMs-for-Dialogue-Summarization
Implemented full and parameter-efficient fine-tuning (PEFT) techniques on the FLAN-T5 model for dialogue summarization. 

Demonstrated the benefits of Low-Rank Adaptation (LoRA) by reducing memory requirements while maintaining high-quality summarization performance.
